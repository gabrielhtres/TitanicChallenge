{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das biliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importa o knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# importa a decision tree\n",
    "from sklearn import tree\n",
    "# importa o random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# importa o módulo de métricas\n",
    "from sklearn import metrics\n",
    "# importa a função auxiliar para fazer a divisao dos dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "# importa o encoder para transformar as classes em texto em números\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# importa o standard scaler para normalizar os dados numéricos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# importa o minmax scaler para normalizar os dados numéricos\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o csv de treino e teste das classes e remove as linhas que possuem idade, porto de embarque ou tarifa nulas\n",
    "train_x = pd.read_csv('train.csv')\n",
    "train_x = train_x.dropna(subset=['Age']).dropna(subset=['Embarked']).dropna(subset=['Fare'])\n",
    "train_y = train_x['Survived']\n",
    "train_x.pop('Survived')\n",
    "test_x = pd.read_csv('test.csv')\n",
    "test_y = pd.read_csv('gender_submission.csv')\n",
    "merged = pd.merge(test_x, test_y, on='PassengerId')\n",
    "merged = merged.dropna(subset=['Age']).dropna(subset=['Embarked']).dropna(subset=['Fare'])\n",
    "test_x = merged.drop(['Survived'], axis=1)\n",
    "test_y = merged['Survived']\n",
    "\n",
    "# Removendo colunas que não serão utilizadas\n",
    "train_x.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "test_x.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "# Transformando a variável Sexo para numérica (male e female para 1 e 0, respectivamente) e a variável Embarked para numérica (C, Q e S para 0, 1 e 2, respectivamente)\n",
    "le = LabelEncoder()\n",
    "le.fit(train_x['Sex'])\n",
    "train_x['Sex'] = le.transform(train_x['Sex'])\n",
    "le.fit(test_x['Sex'])\n",
    "test_x['Sex'] = le.transform(test_x['Sex'])\n",
    "\n",
    "le.fit(train_x['Embarked'])\n",
    "train_x['Embarked'] = le.transform(train_x['Embarked'])\n",
    "le.fit(test_x['Embarked'])\n",
    "test_x['Embarked'] = le.transform(test_x['Embarked'])\n",
    "\n",
    "train_x.head()\n",
    "test_x.head()\n",
    "\n",
    "# Normalizando os dados com standard scaler\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(train_x[['Age']])\n",
    "# train_x['Age'] = scaler.transform(train_x[['Age']])\n",
    "# scaler.fit(test_x[['Age']])\n",
    "# test_x['Age'] = scaler.transform(test_x[['Age']])\n",
    "# scaler.fit(train_x[['Fare']])\n",
    "# train_x['Fare'] = scaler.transform(train_x[['Fare']])\n",
    "# scaler.fit(test_x[['Fare']])\n",
    "# test_x['Fare'] = scaler.transform(test_x[['Fare']])\n",
    "\n",
    "# Normalizando os dados com min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_x[['Age']])\n",
    "train_x['Age'] = scaler.transform(train_x[['Age']])\n",
    "scaler.fit(test_x[['Age']])\n",
    "test_x['Age'] = scaler.transform(test_x[['Age']])\n",
    "scaler.fit(train_x[['Fare']])\n",
    "train_x['Fare'] = scaler.transform(train_x[['Fare']])\n",
    "scaler.fit(test_x[['Fare']])\n",
    "test_x['Fare'] = scaler.transform(test_x[['Fare']])\n",
    "\n",
    "# Normalizando os dados com divisão pelo máximo\n",
    "# test_x['Age'] = test_x['Age'] / test_x['Age'].max()\n",
    "# test_x['Fare'] = test_x['Fare'] / test_x['Fare'].max()\n",
    "# train_x['Age'] = train_x['Age'] / train_x['Age'].max()\n",
    "# train_x['Fare'] = train_x['Fare'] / train_x['Fare'].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.8851963746223565\n",
      "F1-score: 0.8851963746223565\n",
      "Precision: 0.8851963746223565\n",
      "Recall: 0.8851963746223565\n"
     ]
    }
   ],
   "source": [
    "# # Treinando o modelo KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=19)\n",
    "\n",
    "#Treinamos o modelo utilizando treino X e treino Y\n",
    "knn.fit(train_x, train_y)\n",
    "\n",
    "# Realizando a predição com o modelo treinado\n",
    "pred_y = knn.predict(test_x)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(pred_y, test_y))\n",
    "print(\"F1-score:\", metrics.f1_score(pred_y, test_y, average='micro'))\n",
    "print(\"Precision:\", metrics.precision_score(pred_y, test_y, average='micro'))\n",
    "print(\"Recall:\", metrics.recall_score(pred_y, test_y, average='micro'))\n",
    "\n",
    "# Percorrendo entre 1 e 50 para encontrar o melhor valor de K (encontrado o valor 19)\n",
    "# for i in range(1, 51):\n",
    "#     # Treinando o modelo KNN\n",
    "#     knn = KNeighborsClassifier(n_neighbors=i)\n",
    "\n",
    "#     #Treinamos o modelo utilizando treino X e treino Y\n",
    "#     knn.fit(train_x, train_y)\n",
    "\n",
    "#     # Realizando a predição com o modelo treinado\n",
    "#     pred_y = knn.predict(test_x)\n",
    "\n",
    "#     print(\"K =\", i)\n",
    "#     print(\"Accuracy:\", metrics.accuracy_score(pred_y, test_y))\n",
    "#     print(\"F1-score:\", metrics.f1_score(pred_y, test_y, average='micro'))\n",
    "#     print(\"Precision:\", metrics.precision_score(pred_y, test_y, average='micro'))\n",
    "#     print(\"Recall:\", metrics.recall_score(pred_y, test_y, average='micro'))\n",
    "#     print('--------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.8338368580060423\n",
      "F1-score: 0.8338368580060423\n",
      "Precision: 0.8338368580060423\n",
      "Recall: 0.8338368580060423\n"
     ]
    }
   ],
   "source": [
    "# Geramos a árvore de decisão utilizando gini como critério de cálculo de Information Gain\n",
    "# clf = tree.DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\", random_state=42, max_depth=8)\n",
    "# clf = tree.DecisionTreeClassifier(criterion=\"log_loss\", random_state=42)\n",
    "\n",
    "#Treinamos o modelo utilizando treino X e treino Y\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "# Predizemos o conteúdo do teste X\n",
    "pred_y = clf.predict(test_x)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(pred_y, test_y))\n",
    "print(\"F1-score:\", metrics.f1_score(pred_y, test_y, average='micro'))\n",
    "print(\"Precision:\", metrics.precision_score(pred_y, test_y, average='micro'))\n",
    "print(\"Recall:\", metrics.recall_score(pred_y, test_y, average='micro'))\n",
    "\n",
    "# Percorrendo entre 1 e 50 para encontrar o melhor valor de níveis da árvore (encontrado o valor 8 com o critério de entropia)\n",
    "\n",
    "# for i in range(1, 51):\n",
    "#     # Treinando o modelo KNN\n",
    "#     clf = tree.DecisionTreeClassifier(criterion=\"entropy\", random_state=42, max_depth=i)\n",
    "\n",
    "#          #Treinamos o modelo utilizando treino X e treino Y\n",
    "#     clf.fit(train_x, train_y)\n",
    "\n",
    "#     # Predizemos o conteúdo do teste X\n",
    "#     pred_y = clf.predict(test_x)\n",
    "\n",
    "#     print(\"K =\", i)\n",
    "#     print(\"Accuracy:\", metrics.accuracy_score(pred_y, test_y))\n",
    "#     print(\"F1-score:\", metrics.f1_score(pred_y, test_y, average='micro'))\n",
    "#     print(\"Precision:\", metrics.precision_score(pred_y, test_y, average='micro'))\n",
    "#     print(\"Recall:\", metrics.recall_score(pred_y, test_y, average='micro'))\n",
    "#     print('--------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.8217522658610272\n",
      "F1-score: 0.8217522658610272\n",
      "Precision: 0.8217522658610272\n",
      "Recall: 0.8217522658610272\n"
     ]
    }
   ],
   "source": [
    "# Geramos a floreta gini como critério de cálculo de Information Gain\n",
    "clf = RandomForestClassifier(n_estimators=80, criterion='entropy', random_state=42)\n",
    "\n",
    "#Treinamos o modelo utilizando treino X e treino Y\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "# Predizemos o conteúdo do teste X\n",
    "pred_y = clf.predict(test_x)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(pred_y, test_y))\n",
    "print(\"F1-score:\", metrics.f1_score(pred_y, test_y, average='micro'))\n",
    "print(\"Precision:\", metrics.precision_score(pred_y, test_y, average='micro'))\n",
    "print(\"Recall:\", metrics.recall_score(pred_y, test_y, average='micro'))\n",
    "\n",
    "# Percorrendo entre 1 e 100 para encontrar o melhor valor de níveis das árvores (encontrado o valor 80 com o critério de entropia)\n",
    "\n",
    "# for i in range(1, 101):\n",
    "#     # Geramos a floreta gini como critério de cálculo de Information Gain\n",
    "#     clf = RandomForestClassifier(n_estimators=i, criterion='entropy', random_state=42)\n",
    "\n",
    "#     #Treinamos o modelo utilizando treino X e treino Y\n",
    "#     clf.fit(train_x, train_y)\n",
    "\n",
    "#     # Predizemos o conteúdo do teste X\n",
    "#     pred_y = clf.predict(test_x)\n",
    "\n",
    "#     print('K = ', i)\n",
    "#     print(\"Accuracy:\", metrics.accuracy_score(pred_y, test_y))\n",
    "#     print(\"F1-score:\", metrics.f1_score(pred_y, test_y, average='micro'))\n",
    "#     print(\"Precision:\", metrics.precision_score(pred_y, test_y, average='micro'))\n",
    "#     print(\"Recall:\", metrics.recall_score(pred_y, test_y, average='micro'))\n",
    "#     print('--------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação dos resultados\n",
    "\n",
    "Baseado nos resultados identificados após o treinamento dos modelos com os algoritmos KNN, Decision Tree e Random Forest, realizando a manipulação dos hiperparametros para encontrar as melhores métricas em cada um e baseando a análise no cálculo das métricas Accuracy, F1-score, Precisão e Recall, foi possível identificar que o modelo KNN apresentou os melhores resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
